https://github.com/apachecn/AiLearning



# 概述

机器学习深度学习本质上还是通过大量的 ‘判断’ 来完成学习的，模型训练出参数用于判断。

人类的大脑底层神经元 只有 ‘判断’ 这一种根本性逻辑吗？我猜想，还有连接（联想），这个未必是通过判断来实现的。还有连接脉络，

人在学习过程除了模拟最底层神经元，是不是还有一些中间过程可以探索，比如一些学习方法，哪些忘记知识后留下来的东西。



一个模型构建的只是一个系统，解决的只是一个专门的事，智能势必要解决多领域事务，要组织起来不同领域的进行碰撞

灵感的来源，交流，输入与



建立一个 大脑决定行为 的模型，用机器模拟



什么时候学习，什么时候思想创造，好奇心之后怎么思考







### 定义

机器学习从 **海量数据** 获取 **有用信息**，它主要使用**归纳**、**综合**而不是演绎



### 发展

模式识别 --》机器学习（步骤明确）--》深度学习



### 结构

![这里写图片描述](picture/机器学习结构-1603766150764)



### 问题

偏差（准确）方差（稳定）权衡

海量数据+简单处理 或 少量数据+复杂处理

输入空间的维数

噪声



### 获取知识方法

规则集（专家/拍脑袋）

统计分布

模型



# 监督学习



### 数据

特征

label



### 任务

分类 

回归



### 算法

##### 线性回归

线性回归利用普通最小二乘法来求解线性模型 y=w1x1+w2x2+w3x3 的一系列 w

要求每个x相互独立，没有相关性。否则会对随机误差很敏感

目标函数：实际数据和预测数据之间的残差平方和最小



##### 逻辑回归



##### 决策树

可以可视化、注意要有泛化能力、决策树很难表示出异或，奇偶或复用器这些概念

决策树算法有ID3, C4.5, C5.0 和 CART树



GBDT

k-近邻

朴素贝叶斯

岭回归

支持向量机 svm







# 非监督学习



### 数据

无label



### 任务

聚类

降维

密度估计



### 算法

kmeans

DBSCAN



### 技术实现

统计数据密度估计

寻求，总结和解释数据的主要特点

处理数据的数据挖掘方法



# 强化学习



### 算法

马尔可夫算法



















方差与偏差



偏差：所有预测产生的误差的平均

方差：反映模型稳定性，反映对数据集变化敏感，就是过拟合了（很好的拟合了所有数据点，但是没拟合好真实曲线）

![a6509a4f7b1838eb6d76d30036a00ffd](picture/a6509a4f7b1838eb6d76d30036a00ffd.png)

图1高偏差，图3高方差。

高偏差，训练集得分低。

高方差，训练集高，验证集低。



























机器学习的本质

![机器学习本质](picture/机器学习本质-1603347415253.jpg)







![image-20220120153943545](picture/image-20220120153943545.png)





![image-20220120153950128](picture/image-20220120153950128.png)





监督学习，非监督学习，深度学习，强化学习，迁移学习





泛化能力，在哪都准

