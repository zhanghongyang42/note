# 分类指标

### 混淆矩阵

confusion_matrix	混淆矩阵

```python
#二分类，多分类
from sklearn.metrics import confusion_matrix
y_true = [2, 0, 2, 2, 0, 1]
y_pred = [0, 0, 2, 2, 0, 2]
confusion_matrix(y_true, y_pred)
```



分类报告

```python
from sklearn.metrics import classification_report
y_true = [0, 1, 2, 2, 0]
y_pred = [0, 0, 2, 1, 0]
target_names = ['class 0', 'class 1', 'class 2']
print(classification_report(y_true, y_pred, target_names=target_names))
```



多标签混淆矩阵

```python
y_true = np.array([[0, 0, 1],[0, 1, 0],[1, 1, 0]])
y_pred = np.array([[0, 1, 0],[0, 0, 1],[1, 1, 0]])

mcm = multilabel_confusion_matrix(y_true, y_pred)
tn = mcm[:, 0, 0]
tp = mcm[:, 1, 1]
fn = mcm[:, 1, 0]
fp = mcm[:, 0, 1]
recall = tp / (tp + fn)
```



### accuracy

```python
#应用于二分类，多分类，多标签评价
import numpy as np
from sklearn.metrics import accuracy_score

y_pred = [0, 2, 1, 3]
y_true = [0, 1, 2, 3]

accuracy_score(y_true, y_pred)
```

```python
#二分类多标签情况，每条数据的几个y有一个没对应，即为该条数据的y没对应。根据对应结果计算准确度
import numpy as np
from sklearn.metrics import accuracy_score

y_true = np.array([[0, 0], [1, 1],[1,1]])
y_pred = np.ones((3, 2))

print(accuracy_score(y_true,y_pred))
```



### precision、recall、f1

![3771db7af1e3b7bf33e15ec20d278f39](picture/3771db7af1e3b7bf33e15ec20d278f39.png)



![407341c3d4d055b857bb3229003b9daf](picture/407341c3d4d055b857bb3229003b9daf.png)



![b3edbb24837112f795a22e3574457416](picture/b3edbb24837112f795a22e3574457416.png)

```python
#二分类、多分类、多标签
from sklearn import metrics
y_pred = [0, 1, 0, 0]
y_true = [0, 1, 0, 1]

#average，评价多分类或者多标签分类的必须参数
#https://blog.csdn.net/hlang8160/article/details/78040311
metrics.precision_score(y_true, y_pred,average='macro')

metrics.recall_score(y_true, y_pred)

metrics.f1_score(y_true, y_pred)

#也是f1分数，beta>1，说明recall更重要
metrics.fbeta_score(y_true, y_pred, beta=2)
```

```python
import numpy as np

y_true = np.array([0, 0, 1, 1])
y_scores = np.array([0.1, 0.4, 0.35, 0.8])

#计算出不同阈值下的精确率和召回率
from sklearn.metrics import precision_recall_curve
precision, recall, threshold = precision_recall_curve(y_true, y_scores)
```



### ROC曲线的AUC

auc的解释有两种，一种是代表模型的分类性能，一种可以解释为排序中，把两条数据排序正确的概率。

auc的理论值为0.5-1。

auc的合理数值跟场景有关，如图像分类的场景中，auc需要达到0.95，但是在电商点击率与转化率预估中，可能达到0.7-0.8即可，其中，转化率的标准auc大于点击率标准auc，因为转化率场景的是否会产生购买的用户比是否会点击的用户特征差距更大，导致转化率场景的标准auc更搞。https://www.zhihu.com/question/445383673/answer/1742921696

max auc 由数据决定，一种极端情况，两条数据，特征一样，label不同。不管怎么做，auc也只能0.5，所以数据特征差异性不大的数据集，max_auc可能远远达不到1，可以通过预测训练集数据来大致看一下max auc。https://zhuanlan.zhihu.com/p/24217322



```python
#ROC曲线绘制
import numpy as np
from sklearn.metrics import roc_curve

y = np.array([1, 1, 2, 2])
scores = np.array([0.1, 0.4, 0.35, 0.8])

fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2)

plt.plot(fpr, tpr, lw=2, label='ROC curve (area = {:.2f})'.format(auc))
plt.plot([0,1], [0, 1], 'r--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc='lower right')
plt.show()
```

```python
#AUC得分计算
import numpy as np
from sklearn.metrics import roc_auc_score

y_true = np.array([0, 0, 1, 1])
y_scores = np.array([0.1, 0.4, 0.35, 0.8])

roc_auc_score(y_true, y_scores)
```



# 回归指标

### 最大误差

```python
from sklearn.metrics import max_error
y_true = [3, 2, 7, 1]
y_pred = [9, 2, 7, 1]
max_error(y_true, y_pred)
```



### 平均绝对误差 (MAE) 

```python
from sklearn.metrics import mean_absolute_error
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]
mean_absolute_error(y_true, y_pred)

#多标签
y_true = [[0.5, 1], [-1, 1], [7, -6]]
y_pred = [[0, 2], [-1, 2], [8, -5]]
mean_absolute_error(y_true, y_pred)
```



### 均方误差（MSE）

```python
from sklearn.metrics import mean_squared_error

y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]

mean_squared_error(y_true, y_pred)

#多标签
y_true = [[0.5, 1], [-1, 1], [7, -6]]
y_pred = [[0, 2], [-1, 2], [8, -5]]
mean_squared_error(y_true, y_pred)  
```



### 均方误差对数（MSLE）

```python
from sklearn.metrics import mean_squared_log_error

y_true = [3, 5, 2.5, 7]
y_pred = [2.5, 5, 4, 8]
mean_squared_log_error(y_true, y_pred)  

y_true = [[0.5, 1], [1, 2], [7, 6]]
y_pred = [[0.5, 2], [1, 2.5], [8, 8]]
mean_squared_log_error(y_true, y_pred)  
```



### 中位绝对误差（MedAE）

```python
from sklearn.metrics import median_absolute_error
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]
median_absolute_error(y_true, y_pred)
```



# 模型衰减

模型衰减可以通过训练集和测试集指标之间的差值来 反应模型衰减性能。

差值小，说明泛化性能好，说明模型衰减慢。

如下面举例，B模型效果差一些，但是泛化能力更好，衰减更慢。

| 模型 | 训练集AUC | 测试集AUC | 差值 |
| ---- | --------- | --------- | ---- |
| A    | 0.9       | 0.8       | 0.1  |
| B    | 0.8       | 0.75      | 0.05 |



# 聚类指标

### 兰德指数

```python
#已知真实标签时 对聚类算法的评价
#真实数据一般没有，作为聚类模型选择过程中共识索引(Consensus Index)的一个构建模块是非常有用的

from sklearn import metrics
labels_true = [0, 0, 0, 1, 1, 1]
labels_pred = [0, 0, 1, 1, 2, 2]

metrics.adjusted_rand_score(labels_true, labels_pred)  
```



### 轮廓系数

![8f839ebe5b506fef19bd8cc121b3f557](picture/8f839ebe5b506fef19bd8cc121b3f557.png)

- **a**: 样本与同一类别中所有其他点之间的平均距离。
- **b**: 样本与 *下一个距离最近的簇* 中的所有其他点之间的平均距离。

```python
from sklearn import datasets
from sklearn.cluster import KMeans
from sklearn import metrics

dataset = datasets.load_iris()
X = dataset.data
y = dataset.target

kmeans_model = KMeans(n_clusters=3, random_state=1).fit(X)
labels = kmeans_model.labels_
metrics.silhouette_score(X, labels, metric='euclidean')
```



### 其他

```python
#CH指标
ch = metrics.calinski_harabaz_score(X, label_pred)
print(ch)

#DB指数
davies_bouldin_score = metrics.davies_bouldin_score(X, label_pred)
```

































