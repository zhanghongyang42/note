# 一 、协同过滤

### 1.基本介绍

协同过滤是最简单的推荐算法，思想简单，原理也简单。因为简单，所以有效。

协同过滤：协同就是通过找群体的相似性来推荐。过滤是从 大量用户物品关系中 找出 联系强的部分用户物品。协同过滤就是通过相似度来过滤。



协同过滤分为 基于用户的协同过滤（userCF） & 基于商品的协同过滤（itemCF）。本节主要介绍了基于用户的协同过滤。

基于用户的协同过滤 基本思想：根据相似行为找出相似用户A、B。A曾经购买过的物品a，B可能也喜欢购买a。



### 2.原理过程

##### 2.1评分矩阵

根据用户行为构建 用户-物品评分矩阵。图1

![image-20211215102802330](picture/image-20211215102802330.png)

这是一个19*10的用户物品评分矩阵。

行是所有的用户，列是所有的物品。每个元素是用户对物品的评分，评分代表用户对物品的喜爱程度。



评分分为隐式反馈和显式反馈，用户直接对标的物打分叫做显示反馈，通过用户行为计算出出的评分叫做隐式反馈。

一般很少有显示反馈。而且隐式反馈反应了用户的潜意识，更加准确。



打分规则：

1. 用户没对商品产生行为，打0分或者不打分。

2. 用户对商品产生负面行为，打负分。暂时没有。

3. 用户对商品正面行为，如点击、收藏、加购、购买，打1，2，3，5分。

   这里打分标准的确定方法：拍脑袋、行业经验、赋权法、后期优化

4. 如果我们暂时没有埋点日志，只有购买数据，直接01打分也可。



##### 2.2相似度计算

很多种算法都用到了 相似度计算/相关系数计算/距离计算。相似度计算有很多种方法，各有优劣，这里介绍3种。



**jaccard 相似度**

jaccard = a交b/a并b									：损失了评分大小信息。



**余弦相似度**

cosθ = a·b / |a|*|b|									：假设所有用户的评价标准相同，用户主观评价时评价标准可能不同。



**改进的余弦相似度**

a,b为用户，i为商品。本质是两用户的相同交互行为越多，得分越高。适用于01得分。
$$
cosθ = \sum_imin(a_i,b_i)\div\sqrt{\sum_i(a_i)}\sqrt{\sum_i(b_i)}
$$


**皮尔逊相关系数**

皮尔逊corr = 把矩阵每个数都减去 所在行均值，再余弦。



综上，我们选择 jaccard相似度 或者 余弦相似度 即可。



##### 2.3协同评分

给没有行为的 用户物品计算一个得分。



hard协同：卡一个相似度分值。给用户推荐他相似用户购买过的商品。

soft协同：计算出用户没有产生行为的物品得分，根据得分取TOPN给用户推荐商品。

​					score(u1,i1) = 求和（其他用户对i1评分*其他用户与u1相似度）/ 求和（其他所有用户与u1相似度）。避免了U1是高频用户时评分过高。



这里我们采用的是 soft协同。



### 3.所需数据

通过上面的基于用户协同过滤的过程，我们可以得出所需数据格式。

理论上我们的用户行为数据应该通过埋点日志得到，如果可以从业务数据库提取的话，也可以暂时替代。



用户id	物品id	购买	[点击]	[收藏]	[加购]	购买时间	[点击时间]	[收藏时间]	[加购时间]

```
生产库中 订单商品明细 有 593.4236
构成矩阵的话，用户 * 商品 会构成 4.1327 * 81.2061 的矩阵。
大概300多亿的矩阵中有500多万的数据是
```



### 4.代码实现（略）



### 5.优化

**分数衰减**

因为用户的兴趣是变化的，所以基于用户行为的打分需要随时间进行衰减。下面的时间衰减公式是一个经验公式，其中 n 代表 行为时间 与 当前时间的差值。
$$
w(n) = 0.5 + 0.5^{(1+0.02n)}
$$


**数据优化**

如果用户数过多或者活跃用户占比过少时，可以取七天内活跃用户做评分矩阵。避免计算事倍功半。

活跃用户 -- 对商品的评分影响大 -- 活跃用户一般都容易活跃于热门商品 -- 长尾物品不被推荐。但是我们的活跃用户不一定是活跃在热门商品中。



**工程优化**

评分矩阵可稀疏存储。

具体需要在写代码过程中再说。



**算法优化**

如果评分矩阵中评分过少的时候，可能会出现相似用户过多的情况。这时候可以使用用户聚类，找出相似用户。



### 6.场景

基于用户的协同过滤是个性化推荐。可用于首页推荐。



基于用户的协同过滤和基于物品的协同过滤原理是完全一样的。

从工程实现上来说，哪个数据量小，哪个就易于实现。我们有10万用户，却有过亿的商品数据，所以基于物品协同过滤计算量过大。

从算法效果上看，如果短期内用户或商品哪一个增长迅速，哪一个的协同过滤效果就会不太稳定。我们是ToB的业务，用户总体稳定，适用基于用户的协同过滤。

从推荐结果上看，基于用户的协同过滤找出的某个群体内的热门物品推荐给这个群体的其他人。基于物品的协同过滤本人的兴趣爱好，更加个性化。



### 7.总结

实际中还需要观察理解数据 调整流程，比如矩阵过于稀疏，用户之间没有 具有相同行为相同行为的商品，都不能得到有效的协同过滤推荐结果。

以后如果有时间，还可以尝试实现 基于物品的协同过滤。



# 二、关联规则

### 1.基本介绍

通过一个经典小故事了解什么是 关联规则

```
“啤酒与尿布”的故事

该故事发生在20世纪90年代的美国沃尔玛超市中，沃尔玛的超市管理人员分析销售数据时发现了一个令人难以置信的现象：在某些特定的情况下，“啤酒”与“尿布”两件看上去毫无关系的商品会经常出现在同一个购物篮(用户一次购物所买的所有商品形象地称为一个购物篮)中，这种独特的销售现象引起了管理人员的注意，经过后续调查发现，这种现象出现在年轻的父亲身上。

 在美国有婴儿的家庭中，一般是母亲在家中照看婴儿，年轻的父亲前去超市购买尿布。父亲在购买尿布的同时，往往会顺便为自己购买啤酒，这样就会出现啤酒与尿布这两件看上去不相干的商品经常会出现在同一个购物篮的现象。沃尔玛发现了这一独特的现象，开始在卖场尝试将啤酒与尿布摆放在相同的区域，让年轻的父亲可以方便地同时找到这两件商品，并很快地完成购物；这样做沃尔玛超市就让这些客户一次购买了两件商品、而不是一件，从而获得了很好的商品销售收入，这就是“啤酒与尿布”故事的由来。
```

所以关联规则就是找到 用户购买了a、e之后，还可能购买 b、c、d 的规则。写成 a、e --> b、c、d ，称为一个关联规则。



### 2.原理概念

项集：若干个项的集合。项多数指代某件商品，项集就是一次购买商品的集合。项集中有两个项，就构成二项集，有三个项，就叫三项集。

频繁项集：频繁出现的项集。常用的频繁项集的评估标准是支持度。

支持度：所有数据中包括该XY项集样本所占的比例，为该项集的支持度。支持度是XY同时被购买的概率。

置信度：包含XY的项集中占包含X项集的比例（即在X给定的情况下，Y出现的条件概率）。置信度是购买X再购买Y的概率。



支持度剪枝理论：如果一个超集是频繁项集，那么它的子集一定是频繁项集。如果一个子集是非频繁项集，那么它的超集一定是非频繁项集。

置信度剪枝理论：如果{bcd}-->{a}置信度小于阈值，那么所有在箭头后有a的关联规则，如{cd}-->{ab}置信度也会小于阈值。



**Apriori**

算法步骤：

1. 扫描购物篮数据，得到每种商品的支持度，称为候选一项集。
2. 设置支持度阈值（最小支持度），从候选一项集中拿出满足阈值的。称为频繁一项集。
3. 频繁一项集中的项两两组成为二项集，再次删除小于最小支持度的二项集，得到频繁二项集。重复，知道得到所有频繁项集。
4. 从所有频繁项集中 写出 关联规则：即分别用频繁项集中的所有1项，2项...作为X，剩余项作为Y,即可得出所有关联规则。
5. 设置最小置信度，找出所有满足置信度的关联规则。



**FP-Groupth**

![1042406-20170119165427593-1237891371](picture/1042406-20170119165427593-1237891371.png)

FP树：左侧是购物篮数据，项头表是按照商品频数排序。将购物篮数据按照项头表的顺序调整。按照购物篮数据画出FP树，FP树上是每个商品和其计数。



算法步骤：

1. 扫描数据库，得到频繁一项集。根据支持度剪枝理论，删除不满足条件的记录。
2. 剩下的记录按照商品购买的总频数排序。
3. 构建一颗FP树，依次选择购物篮的每条路径。如果有共用的祖先，则对应的公用祖先节点计数加1。
4. 从叶子节点开始挖掘，获得频繁项集。如F开始，频繁2项集为{A:2,F:2}, {C:2,F:2}, {E:2,F:2}, {B:2,F:2}，频繁三项集为{A:2,C:2,F:2}，{A:2,E:2,F:2},...
5. 按照Apriori中找关联规则的方法找出关联规则



### 3.所需数据

可以看出，关联规则算法，只需要订单数据便可完成。

```
一个订单中有多个商品订单数：848898 ,可以尝试。
具体能不能挖掘到频繁项集，还有实际验证一下。
```



### 4.代码实现（略）



### 5.优化

可以通过各种剪枝理论，减少计算量。



### 6.场景

可以用于商品详情页推荐。

也可以用于客户下单完成后的推荐。



# 三、基于内容推荐

‘内容‘ 分为三类：用户信息、商品信息、用户行为



**商品信息**

商品结构化信息/商品基本信息。

```
bl_product_basic_0 及其相关的表。
```



商品标签/分类信息。

具体使用方式为用 最细层级的分类 或者 所有层级的分类 构建one hot 特征向量。

获取标签的方法：让商家、客户、或者我们自己进行人工标注。用 NLP 或者目标检测的方法，从文本视频中提取。 

```
我们目前的  tbl_category 商品分类 表是有的，但是准确度一般，可以用，效果不一定。
```



商品相关文本，图片，音频，视频等信息，暂时不用。



**用户信息**

用户基本信息。

```
用户的人口统计学信息基本没有。
有少量的可用的用户基本信息：地址，研究所，课题，分组，积分等。
```



用户标签/分类信息。这里标签就是商品中标签，所以用户标签的前提是物品已经有了标签。

标签表示用户对哪类商品感兴趣，每个用户可以有多个标签，每个标签都可以有得分权重。

用户标签获取：用户注册时主动选择标签。根据用户历史行为给用户打标签。

```
这部分信息暂时没有，而且用户标签的准确性，严重依赖于商品标签的准确性。
```



**用户行为信息**

评论、收藏、浏览、点击、加购物车、购买等。

内容推荐和协同过滤 不同点是 只会用到用户自身的历史行为，不会涉及到其他用户的行为。

```
订单数据、购物车数据、评论、收藏等表都可以从生产库中获取。
```



### 1.类似物品协同过滤

利用 商品信息+[商品标签] 构建特征矩阵。

根据矩阵计算 物品相似度。也可以利用KNN 方法 计算物品相似度。

根据协同评分的原理，进行打分。

用户购买过某件商品，就把最相似的TopN商品推给他。



### 2.类似用户协同过滤

利用 用户信息+用户行为信息 构建特征矩阵。

根据矩阵计算 用户相似度。也可以利用KNN 方法 计算用户相似度。

根据协同评分的原理，进行打分。

给用户A推荐他的最相似用户B购买过而A没购买过的商品。



### 3.基于商品聚类

利用 商品信息+[商品标签] 构建特征矩阵。

用Kmeans 或者 层次聚类 的方法对商品进行聚类。

将用户历史记录中的标的物的相似标的物推荐给用户。



### 4.基于标签推荐（pass）

使用用户标签 和商品标签。

从用户画像得到用户标签。商品标签做成倒排索引表。

用户的标签 和 倒排索引表中的商品都是有权重的。

根据标签给用户推荐该标签的商品（权重计算略）。



### 5.场景

上面4种方法可以用于不同的场景。

类似物品协同过滤&基于商品聚类 可以用于 商品详情页推荐。

类似用户协同过滤&基于标签推荐 可以用于首页推荐。

基于标签推荐 也可以考虑直接推给 客户他可能感兴趣的标签。



当协同过滤没有给用户足够的推荐结果，可以使用基于内容的推荐结果补充。



### 6.优化

考虑用户 行为变化/兴趣改变/兴趣衰减 的问题。-



# 四、总结

召回一般完全离线运算，把推荐结果存入数据库即可。



很多复杂算法的结果都跑不过baseline，很多学术界的研究在工业界也并不能落地。

但是深度学习确实有效，不过是用的数据太多，模型太重。除了主流需求外，其他小需求还是需要轻量级模型以20%算力达到80%效果。



召回中的算法基本都是特有的推荐算法，比较巧妙，所需数据特征数不多。但是排序算法（尤其是使用了深度学习）还是需要大量特征来实现的。

工程和数据是算法的准备工作，所以我们第一期只上了简单的召回算法，后期肯定会上排序算法，所以我们有时间的话要尽量做可复用可扩展的数据。

以后推荐规模大起来以后，模型变多，使用算法复杂。肯定要追加机器配置。排序模型的话除了写代码，数据分析和模型训练也都是很耗时的。

数据这方面可能说还是一个程度问题，现在这种程度也可以开始，可能效果一般。商品标签数据 和 用户基本的信息的补全可以 放进优化阶段。



用户画像和排序算法的大概介绍。



































































































