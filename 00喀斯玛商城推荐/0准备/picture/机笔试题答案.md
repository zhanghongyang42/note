# 机器学习

回答意思对即可，没有太标准的答案。



1. 损失函数和目标函数的区别。

```
损失函数 ：模型输出与真实标签的差值，描述经验风险。
目标函数：损失函数+正则项，描述结构风险。
```

2. 正则化的作用，可简写。

```
作用：减小参数大小或数量，防止过拟合。
```



3. 标准化、归一化 、中心化统称为无量纲化，对数据进行无量纲化有哪些作用。

```
加快速度（梯度和矩阵为核心的算法中，譬如逻辑回归，支持向量机，神经网络）。
统一量纲，提升精度（在距离类模型，譬如K近邻，K-Means聚类中） 。  
```

4. Labelencoder和oneencoder编码的区别与应用场景。对id类特征采用什么编码方式。

```
LableEncode 对有序特征进行编码。
onehotencode 对无序特征进行编码。
id类特征采用meanencoder或者ont+pca或者特征哈希的方法。
```

5. Wrapper和Embedded都是利用模型训练好后的`coef_` 属性 或 `feature_importances_` 属性来选择特征的，这两类特征选择方法的不同点在哪里

```
Wrapper是用模型算出所有特征的得分，排除几个特征，多次迭代重复这个过程。
Embedded是单独算出每个特征在模型上的得分，设置阈值，删除特征。
```



6. 以XGB为例，简述一下你的调参过程。

```
经验调参，交叉验证，网格搜索。
具体参数树个数，树深度，并行度等参数都可以调整。
```

7. LR（逻辑回归）模型能否做回归，为什么

```
不能。
逻辑回归是线性模型+sigmod函数组成的，LR的预测的结果是为某类的概率，而不是label的值，所以不能用于回归。
```



8. 写出精确率、召回率、f1的含义，公式也可。

```
精确率（Precision），查准率。即正确预测为正的占全部预测为正的比例。
召回率（Recall），查全率。即正确预测为正的占全部实际为正的比例。
F1值，F1值为精确率和召回率的加权平均数。
```

9. 写出两个聚类模型的评价指标。

```
兰德指数、Silhouette 系数、CH指标、DB指数等。
```



10. 一般正负样本比例达到多少算做失衡，样本不均衡有什么影响，怎么解决。

```
一般达到1：10量级就会出现样本不均衡的现象。
样本不均衡会使预测结果偏向样本数较多的分类，使得模型准确率高但是AUC低。
通过调整模型的分类权重&分类阈值 或者数据采样的方式解决。
```

11. 怎么解决模型过拟合问题。

```
正则化
数据少时，加数据
Early stopping
DropOut
```



12. 写出逻辑回归和GBDT的模型原理，可不用推导公式。

```
逻辑回归
LR模型 = sigmod + 线性模型

1.初始化LR模型，给出随机参数。
2.构建损失函数，单次预测结果满足伯努利分布，对所有结果的伯努利分布做极大似然估计，取log，即构成交叉熵损失函数。
3.对损失函数使用梯度下降法求出最小值，即得出LR 模型参数。
```

```
GBDT
GBDT是boosting集成模型，由多颗cart树串联组成。

1.首先训练第一个cart树，使用平方损失划分节点。同cart树模型，不再赘述。
2.定义残差，即cart的预测值与真实值的差距。对于平方损失来说，残差 = 真实值-预测值，对于其他损失，可以使用 损失函数的偏导 作为残差。
3.第二颗cart树把残差作为目标值继续训练。
4.直到训练完所有的cart树，然后把每棵树的结果加和。
```



# 深度学习

深度学习这不是很懂，大概出了一下题。



1. Relu激活函数在零点是否可导？不可导的话反向传播算法中怎么处理。

```
不可导。
间断点的求导按左导数来计算。也就是默认情况下（negative_slope=0）,间断点处的导数认为是0.
```

2. Relu激活函数的优缺点？

```
优点：
    解决了梯度消失、爆炸的问题
    计算方便，计算速度快，求导方便
    加速网络训练
缺点：
    由于负数部分恒为0，会导致一些神经元无法激活
    输出不是以0为中心
```

3. 梯度消失和梯度爆炸的问题是如何产生的？如何解决？

```
由于反向传播过程中，前面网络权重的偏导数的计算是逐渐从后往前累乘的，如果使用激活函数的话，由于导数小于1，因此累乘会逐渐变小，导致梯度消失，前面的网络层权重更新变慢；如果权重本身比较大，累乘会导致前面网络的参数偏导数变大，产生数值上溢。

1.使用ReLU等激活函数，梯度只会为0或者1，每层的网络都可以得到相同的更新速度
2.采用LSTM
3.进行梯度裁剪(clip), 如果梯度值大于某个阈值，我们就进行梯度裁剪，限制在一个范围内
4.使用正则化，这样会限制参数  的大小，从而防止梯度爆炸
5.设计网络层数更少的网络进行模型训练
```

4. 简单介绍一下BERT，MLM是什么。

```
首先BERT是一个无监督学习的模型，本质是一个denoised auto encoding模型；
其次它的主要架构和transformers的encoder部分相同；
主要贡献点在于Bidirectional，传统的pretrain基本思想都是language model，只能看到一端的信息，这限制了与训练模型的表达能力；
为了实现Bidirectional的学习，提出了masked language mode(MLM)；
为了实现text-pair的学习，利用了next sentence prediction；

MLM相当于增加了一些noise，传统的language model是直接根据上文预测下一个词，这里利用了双向信息，根据上下文去预测当前的词；mask掉15%的词去训练模型；
```

5. 请介绍下你知道的文本表征的方法(词向量)

```
基于 one-hot、tf-idf、textrank；
主题模型：LSA（SVD）、pLSA、LDA；
基于词向量的固定表征：Word2vec、FastText、GloVe；
基于词向量的动态表征：ELMo、GPT、BERT
```

6. LSTM相对RNN有什么特点

```
RNN，是一种用于处理序列数据的神经网络。相比一般的神经网络来说，他能够处理序列变化的数据。
LSTM，是一种特殊的RNN，主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的RNN，LSTM能够在更长的序列中有更好的表现。
```



# 大数据（选做）

1. 简述HDFS内存和文件维护元数据的过程（启动时、运行时怎么维护，元数据合并过程）。

```
1.启动时，namenode中 Fsimage文件读进内存，edits文件读进内存，文件块位置定时保存进内存。
2.文件发生变化时，先写进edits文件,再进内存元数据。
3.元数据合并时，Secondnarynamenode 发出合并请求, 设为一个checkpoint，Fsimage和edits复制到snn，snn合并Fsimage和edits为一个新的Fsimage，新Fsimage发给nn，新的edits替换旧的edits。
```

2. ​	简述YARN的三种调度机制。

```
FIFO调度器：先进先出。小作业会被阻塞，不适合共享集群。
容量调度器：留下一部分资源给小作业用。会降低大作业效率。
公平调度器：每个队列动态的平分资源，队列内每个作业也平分资源。
```

3. 简述Spark出现数据倾斜问题的解决思路。

```
调整并行度
使用自定义 Partitioner
给倾斜 Key 加上随机前缀
```

4. 简述Spark job提交的全流程（DAGScheduler、TaskScheduler、executor怎么工作）。

```
SparkContext 启动调度程序（DAGScheduler 和 TaskScheduler） 
DAGScheduler：根据shuffle算子把作业分解为若干Stage，并构建DAG。
TaskScheduler：读取executor列表，构建任务到executor的映射，将任务分配给内核中的executor，默认一个executor一个任务。
executor：确保JAR包和依赖都是最新的，反序列化任务代码，执行任务代码，序列化执行结果，返回driver。
```

5. 简述spark on hive 和 hive on spark的区别。

```
Hive on Spark：Hive 存储元数据。Spark采用RDD执行。HQL语法，Hive 负责SQL的解析优化。
Spark on Hive : Hive 存储元数据。Spark采用DataFrame执行。Spark SQL语法，Spark 负责SQL解析优化。
```

6. 写出spark的wordcount 代码实现。

```scala
sc.textFile("file:///sparkdatas/wordcount.txt").flatMap(_.split(" ")).map((_,1)).reduceByKey(_ + _).collect
```

7. 简述hive内部表和外部表区别，分区表和分桶表是什么。

```
内部表：删除内部表，删除表元数据和数据。内部表存储在默认路径。
外部表：删除外部表，删除元数据，不删除数据。外部表存储在指定路径。
分区表：将表按照分区字段（一般是时间）分区，分区的字段名和字段值存储在分区目录的名称里。查询时指定分区键查询即可。加快CRUD速度。
分桶表：指定表的某一列字段，按照哈希取模的方式随机、均匀的分发到各个桶文件中。加快join速度。
```



# SQL（选做）

1. 请给出下面sql查询语句的执行顺序，例：form--where--。

select count(*) from 表名 where 条件 group by 分组字段 having 分组后条件 order by 排序字段

```
from -- where -- group by -- having -- select -- order by
```



2. 请写sql对下表每个人的收入进行累计求和。表名称table_a，id为主键

```sql
SELECT max(a.id),sum(b.money) FROM 
nm a
JOIN 
nm b
ON
a.id>=b.id
GROUP BY a.id
```



3. 写sql求table_a减去table_b差集，Name为主键

```sql
SELECT Name FROM 
table_a
LEFT JOIN table_b 
on table_b.Name=table_a.Name
WHERE table_b.Name IS NULL;
```



# 数据结构（附加）

1. 给定一个非空数组，返回此数组中 第三小的数 。并给出所用算法的时间复杂度。

```java
public static int[] selectionSort(int[] array) {
    if (array.length == 0)
        return array;
    for (int i = 0; i < array.length; i++) {
        int minIndex = i;
        for (int j = i; j < array.length; j++) {
            if (array[j] < array[minIndex]) //找到最小的数
                minIndex = j; //将最小数的索引保存
        }
        int temp = array[minIndex];
        array[minIndex] = array[i];
        array[i] = temp;
    }
    return array[2];
}

时间复杂度n方
```



2. 给定单链表的头节点 head ，请你反转链表，并返回反转后的链表。可自行定义链表对象。

```java
public static class Node { 
    public int value; 
    public Node next; 
    public Node(int data) { 
        this.value = data; 
    } 
} 

public static Node reverseList(Node node) { 
    Node pre = null; 
    Node next = null; 
    while (node != null) { 
        next = node.next; 
        node.next = pre; 
        pre = node; 
        node = next; 
    } 
    return pre; 
} 
```



# linux命令（附加）

1. 递归文件删除命令

```shell
rm -rf 
```

2. 动态显示文件最后20行

```shell
tail -20f
```

3. 将aaa.tar 解包到指定路径 /service

```shell
tar -xvf ddd.tar -C /service			
```

 

































 



 

 