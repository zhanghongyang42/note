# 一、推荐系统

**什么是推荐系统**

推荐技术是机器学习的一个分支，根据用户在产品上的行为记录，结合用户自身和“标的物”的信息，来为用户推荐可能感兴趣的物品。

为用户提供更优质的服务，同时为商家和平台赚取更多的利润。



**为什么要用推荐系统**

可选择的商品过多，个人通过浏览或搜索很难发现自己感兴趣或最适合自己的商品时，需要我们帮助用户匹配更合适的商品。



**推荐系统基本流程**

1.数据收集：通过业务数据库，用户行为日志等多种途径收集数据。

2.ETL：将收集来的数据过滤加工，变成结构化的可用数据，构建特征仓库。



3.特征工程：将数据变成数学模型所能理解和处理的，也是将算法工程师的业务理解加入数据的过程。

4.推荐算法：模型训练、模型预测、模型的离线评价。是推荐系统的核心模块。

5.推荐结果存储：将推荐好的结果事先存储起来。



6.Web服务模块：推荐系统与用户进行交互的模块。



7.评估模块：主要对推荐结果进行离线模型指标评估和在线业务指标评估。

8.审查模块：对推荐系统结果数据格式的正确性、有效性进行检查。属于逻辑上的“监控”模块。



9.调度模块：对推荐中的各种作业任务进行定时调度，处理依赖关系。

10.监控模块：对状态异常，调度失败，运行报错等任务进行告警和处理。



# 二、总体方向

平台的总销量获得提升，为商城带来利润



### 1.离线的推荐系统

实时推荐系统（信息流推荐）：

1. 基于用户几秒内的行为，实时进行用户推荐。秒级推荐。所见即所得。
2. 代表产品：头条，抖音，淘宝。
3. 适用于快消类产品，短视频，新闻等。
4. 适用于移动端。
5. 提升用户粘性，提升用户使用时长。
6. 实时推荐系统架构：lambda架构，kappa架构
7. 技术选型：Storm、Flink、Spark Streaming



离线推荐系统：

1. 每天更新用户的推荐结果。
2. 适用于小说，电影等长时间的产品。
3. 与实时推荐算法上的差别并不大，但对工程架构，模型构建，交互方式的挑战更小。
4. 技术选型：Spark、MapReduce、TensorFlow



总结：离线推荐工程上的挑战更小。从我们的业务来说，我们的用户购买一般目的性比较明确，没有“逛”的需求，所以比较适合离线的推荐工程。



### 2.技术选型

企业级推荐系统落地强依赖于大数据相关技术，而业界事实上的开源大数据技术标准只有Hadoop生态系统。

如果涉及到我们现有过亿量级表的存储计算的话，也倾向于用大数据技术进行支持。



**现有技术**

基于Hadoop生态系统的机器学习开源框架：Spark MLlib、Flink-ML、Mahout、SystemML。

其他机器学习开源框架：xgboost、scikit-learn、H2O、gensim。以及BAT的开源框架。



深度学习框架：Tensorflow，Pytorch，MXNet等。

可以运行在Hadoop生态系统上的深度学习开源框架：

DeepLearning4J(Java深度学习软件)、TonY（Tensorflow on YARN，LinkedIn开源）、CaffeOnSpark(雅虎开源)、BigDL(基于Spark的深度学习，Intel开源)



**技术选型**

开发语言：Hadoop生态的开发语言一般为**java**或者scala，深度学习的开发语言一般为**python**，底层调用C++。



用于构建推荐系统的机器学习框架：

因为我们的推荐系统对实时性要求不高，而Spark 对批处理，机器学习，表结构数据处理都有良好的支持，所以选用以Spark 为主的Hadoop生态的框架支持。



用于构建推荐系统的深度学习框架：

目前业界主流的深度学习框架还是以python为主，Hadoop生态的深度学习并不完善，而且使用人数较少。Tensorflow上关于推荐系统、排序框架的模块可通过简单修改可以直接用于推荐业务中。所以选用Tensorflow作为构建推荐系统的深度学习框架。



python体系与Hadoop体系的打通：

(1) 将Tensorflow训练好的模型上传到Spark平台，开发基于Java的模型解析工具，让Spark可以解析Tensorflow构建的深度学习模型，并最终进行预测；

(2) Tensorflow训练好深度学习模型后，直接用Tensorflow Servering部署深度学习模型，在Spark侧做推断时，通过调用Servering的接口来为每个用户做推荐。



### 3.触达方式

网页

邮件、短信

APP



**网页**

排行榜推荐（已有热榜）：最热、最新、购买量、搜索量、点击量。

相似推荐：在详情页推荐相似的物品。

个性化推荐：在首页进行的推荐。

搜索推荐：利用推荐的方法重新调整搜索权重。



### 4.推荐系统评估

**离线评估（略）**

模型训练完成后，上线前，对模型效果有一个大概的预计。

准确度评估：不同模型的评估方法不一样。大致可以套用机器学习中的回归、分类、排序的准确度评估方法。一般是对TopN的结果进行评估。

​						RMSE(均方根误差)、MAE(平均绝对误差)。准确率、召回率、F1。MAP。

其他指标：整体覆盖率、多样性。

工程指标：延时性、鲁棒性（数据和工程）、抗并发。



**在线评估**

推荐上线后，通过收集用户的行为数据来评估模型效果。在线评估一般会结合AB测试技术。



直接用漏斗模型对推荐位置进行在线评估：

曝光 -- 点击 -- 加购 --购买

点击率，购买率，转化率。  停留时长等其他行为.....



比较用户的推荐指标和大盘指标：

通过推荐系统产生的购买率比大盘高。我们的网页中是否存在大盘？



通过埋点对长尾物品进行分析：因为大部分推荐算法都对头部热度高的物品表现良好，所以对长尾物品的推荐效果也是评价模型的一个维度。

定义长尾物品：购买量降序后70%的或者低于一定购买量的。

长尾物品是否产生了价值：我们推荐的长尾物品有多少比例用户购买或者点击了。

长尾覆盖率：我们推荐的长尾物品占所有长尾物品的比例。

长尾用户覆盖率：接受到长尾的用户占总接收曝光的用户量。



**主观评估**（略）

问卷调查、电话访谈、见面沟通。



**可能的问题**

离线指标和在线指标可能差异较大。

对部分用户可能不准。



# 三、实现方案 

### 1.数据收集与ETL

目标：利用现有数据以及算法所需数据倒推，尽量快速的建立一个特征仓库。但尽量符合数仓的规范，以便日后支持更多应用。

使用技术：Hive，因为涉及到过亿的表。所以这里采用大数据数仓Hive。



步骤：

1.进行数据与业务的理解，规划出数据仓库需要的大致数据

```
需要与懂数据库，埋点数据和业务的同事进行交流。
预计时间：5-8天。

了解数据库的同事。
现有数据中台
现有埋点数据和埋点位置。
是否自建埋点。埋点方案。
是否有需要但现在没有的数据。
```

2.规划集群资源，安装部署Hive。

```
根据现有数据量和对未来数据量增长的预期，规划hive集群所需资源。
进行Hive的安装部署，需要运维同事帮助。
预计时间：1-3天。
```

3.规划数仓架构，设计数仓表。

```
对即将接入的 生产数据库数据 与日志埋点数据做好表设计。
设计这些数据后续加工需求 ，表和表关系。
需要和熟悉hive架构设计的同事讨论一下，或者我自己摸索一下。
预计时间：3-5天。
```

4.接入生产数据库数据 与 神策或者我们自己的日志埋点数据

```
进行生产数据库的同步：sqoop。
埋点数据的接入:自己维护 ，生成日志文件，flume
需要工程同事帮忙同步。
预计时间：5天-？。
```

5.ETL，做出特征仓库宽表。

```
根据之前设计好的数仓表，由ETL人员进行清洗，加工。
预计时间：需要ETL同事确认。
```



特征仓库举例:

用户行为宽表：浏览，点击，搜索，收藏，加购，购买.......时间戳，频率

用户属性宽表：研究方向，经费额度，感兴趣的分类......

物品属性宽表：分类、价格、厂商、产地.......



### 2.召回算法构建

目标：利用数据，构建模型，计算出推荐结果，并将计算结果存储起来。

使用技术：Spark，Hbase，rocketMQ



**集群的规划和搭建**

预计时间:3天左右

需要运维同事协助

需要一台内网windows开发机。



**基于内容的召回**

基于内容的召回是一个大类，我们先做其中比较简单的一种。

*1.对商品进行聚类，从用户历史行为中的商品所在的类别挑选用户没有操作行为的商品推荐给用户。用户喜欢同类商品中其他商品。*

2.类似协同过滤用商品属性数据计算出商品相似性。通过已有用户商品行为，给喜爱程度打分。算出用户对没产生行为商品的喜爱程度。商品太多，不好计算。

3.对人进行分群，找出同一类人的购买物品，给这类人中没有进行过购买的推荐。预计时间：1个月



**协同过滤**

基于用户的协同过滤，反应某个群体内的物品热门程度，比较适合。预计时间：1个月

根据用户对物品的行为（浏览，点击，搜索，收藏，加购，购买），用户对物品的喜爱程度分。

打分，计算相似性，根据其他打分和相似性算出评分。



**离线评价**

参见上文 推荐系统评估

时间：3-5天



**设计存储结构及脚本部署**

设计推荐结果怎么进行存储，以及存储表。

预计时间：3-5天。



### 3.web服务模块

需要后端同事来做。

前端请求时，从推荐结果数据库取出推荐结果，进行一些逻辑判定（需求我来提）。按前端需求格式返回推荐结果。

前边简单的召回算法的web模块大概就这样，后期涉及到排序，需要在web服务实时计算的时候再行设计。



**冷启动问题**

给新用户更好的体验，新用户留存。

用户冷启动：热榜推荐，根据用户注册信息推荐/每一类都推荐。

物品冷启动：新的物品强制给一定量的曝光。



**审查推荐结果**

对推荐结果的格式，数量等进行审查。



**进行人工设定**

不能配送的区域或者物品要过滤掉。



### 4.在线评价/AB测试

**基于漏斗模型做在线评价**

前端埋点获得曝光列表（一定时长算曝光），点击物品，购买物品：前端同事评估工作量。

将日志数据存到Hive当中。

处理埋点数据，获得在线评价表：ETL同事评估工作量。

读取评价表，计算评价指标，用于保存或展示：3天- ？。



**AB测试**

AB测试模块可以放到下一阶段，有了更多的召回排序算法时再去做。



**推荐反馈**

给用户主动不喜欢推荐，还有原因的按钮



# 四、其他应用

算法发挥作用，非常依赖业务和数据。业务数据我了解还不太不深入，所以这里写一些可能的算法应用。

一般可能是业务人员有一些需求，传统手段解决不了，想一下能否用机器学习的方法解决。

或者算法人员基于自己对数据和业务理解，主动发现痛点，可以改善的地方，来解决。



基于RFM（最近一次购买时间 (Recency)、购买频率 (Frequency)、购买金额 (Monetary)）特征可以衡量用户价值，基于用户价值，可以进行用户分群。更高价值群的客户可以通过CRM客户管理系统进行专门的维护。



物品分类不明确，可以使用NLP技术根据物品名称对物品进行分类，比如字典匹配hmm+crf，或者文本分类的方法进行自动分类。



可以用时间序列的方法对我们商场的浏览量，购买量，营收额做一个预测。

可以对商品销量进行预测。 



可以利用图算法构建商家与用户的关系，分析哪些商家受众最广，哪些用户购买范围大。



CRM可以以后做，客户生命周期管理。



# 五、汇报总结

### 1.时间计划

| 任务模块      | 计划时间                      |
| ------------- | ----------------------------- |
| 数据收集与ETL | 30-40 人天                    |
| 召回算法构建  | 40-50人天                     |
| web服务模块   | 需要同事评估                  |
| 在线评价      | 需要同事评估                  |
|               | 投入时间4-6个月，具体人天不清 |



### 2.集群资源规划

需要大数据运维人员参与规划，待讨论。

安装框架主要包括zookeeper，hadoop，hive，Spark，因为HBase要支持web模块的线上请求，所以需要单独部署，用rocketMQ做解耦。

服务器数量：4-12台

具体配置：需要确定数据量后得出，可以先按标准配置申请。



| 服务器名称 | 安装框架组件                                  | 服务器配置 |
| ---------- | --------------------------------------------- | ---------- |
| node01     | NameNode，ResourceManager                     |            |
| node02     | NameNode，ResourceManager                     |            |
| node03     | zookeeper，JournalNode，DataNode，NodeManager |            |
| node04     | zookeeper，JournalNode，DataNode，NodeManager |            |
| node05     | zookeeper，JournalNode，DataNode，NodeManager |            |
| ........   |                                               |            |

zookeeper、JournalNode

NameNode、DataNode、ResourceManager、NodeManager、jobtracker、tasktracker

hive、spark、HMaster、RegionServer



内存、cpu、硬盘、网络



### 3.汇报总结

可以看到，推荐系统，是一个工程，算法，业务相结合的领域。第一阶段我们的重心主要放在了工程上。算法和业务都涉及的比较浅显。



工程的构建，可能是需要运维，前后端，大数据，ETL等多工种结合的工作。我对这些方面虽然有涉及，但毕竟人力有限。

如果短时间内不好招人的话，能否从内部借调1-2人，主要是大数据运维和数仓构建的工作，我们一起探讨学习。



至于深度学习的人，可能是对算法研究的比较深入，他们大部分都是需要一个好的数据与工程环境，才能发挥作用。



# 六、搜索结果优化

l **基于“规则过滤”**。即基于一些规则，对结果进行过滤。如目前的一些地图搜索，就是根据IP的不同，自动选择搜索的城市。

l **基于“内容过滤**”。在线计算用户模型和结果文档模型的相似度，作为搜索结果排序的要素。典型有http://www.collarity.com/等，还有百度知道的问题推荐，也是利用搜索记录，推荐一些个性化的问题。

l **基于“协同过滤”**。利用用户之间的相似性进行检索结果的过滤和重排。像现在的Bing就是可以优先显示Facebook好友Like推荐的结果。











































 

 