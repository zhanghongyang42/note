线性代数得本质：https://www.bilibili.com/video/av44855426?p=7



# 矩阵相乘-线性变换

红线是这个图的结论

![线性代数-1](picture\线性代数-1.png)

![线性代数-2](picture\线性代数-2.png)

# 行列式

```
矩阵行列式的本质 是 线性变换后 基底 i j 组成的4边形面积变化的比例：证明用处不大，不画了

行列式 = 0 ，线性变换使 基底所决定的空间 进行了降维 ，如i，j共线或到一点。乘以这个行列式的矩阵所得到的结果一定是线性相关的

行列式为负，线性变换不仅改变了面积，还改变了空间定向 ，如二维平面翻面：不用过分理解其物理含义

行列式的计算 ：见其他教材

应用：det（mn）=det（m）det（n），进行复合线性变换面积比例=先进行线性变换的面积比例*再进行线性变换的面积比例
```





# 解线性方程组

https://www.bilibili.com/video/av44855426?p=8视频还要反复看，或者结合教科书理解下面这段内容

![线性代数-3](picture\线性代数-3.png)

https://www.bilibili.com/video/av44855426?p=10



# --------------------

以下为机器学习涉及到的线性代数部分回顾。



# 矩阵

矩阵加法：行列数相等的可以加。对应元素相加。

矩阵乘法：一个数乘以矩阵的所有元素，得到一个新矩阵。

矩阵乘法：m\*n矩阵乘以矩阵n\*o，变成m\*o矩阵。

![img](picture/1a9f98df1560724713f6580de27a0bde.jpg)

`矩阵乘法的作用就是解线性方程式`

矩阵乘法不满足交换律，满足结合律



单位矩阵（E、I）：从左上角到右下角的对角线（称为主对角线）上的元素均为1以外全都为0

对于单位矩阵，有 **AI=IA=A**。



矩阵的逆：如矩阵A是一个矩阵m*m（方阵），如果有逆矩阵，则：![image-20220727170500950](picture/image-20220727170500950.png)



矩阵的转置：行列互换即为矩阵的转置

矩阵的转置基本性质:![image-20220727170649409](picture/image-20220727170649409.png)











































































