本文档中的部分网站需要翻墙后打开，部分命令因为未对源进行更改，所以也需要。命令涉及到的文件名称可按需更改。



# 在外网制作docker镜像

因为prophet时序预测算法安装复杂，离线安装一直没有成功，所以采用的是制作**docker镜像**的方式安装环境。

该步骤制作好的docker镜像也可在本文档同文件夹下的readme.txt中找到。



## 创建centos7环境。

创建与内网环境相同的centos7环境

安装docker：https://yeasy.gitbook.io/docker_practice/install/centos

下载centos7镜像：docker pull cetos:7

创建并进入容器：docker run -it --net=host --name=base_env cetos:7

关于docker的网络模式问题：https://www.cnblogs.com/chenpython123/p/10823879.html



之后的步骤在docker中操作：

从centos7环境向容器中上传文件命令：docker cp xxx.tar base_env:/software/



## 安装anaconda

官网下载安装包：https://www.anaconda.com/products/individual

将安装包上传到我们的docker容器中

安装依赖：yum install -y bzip2

安装anaconda：bash Anaconda3-5.2.0-Linux-x86_64.sh

测试：conda -v

jupyter设置：https://blog.csdn.net/Ni_hao2017/article/details/103346694



## 安装第三方包

我们为了保险起见，防止第三方包安装出问题，复制base环境到一个新环境，再安装。



复制base环境：conda create -n trend_pre --clone base

激活新环境：conda activate trend_pre



安装一些简单的包：

pip install pymysql

pip install elasticsearch6   #与开发环境中的es版本对应

pip install python-kafka

pip install xgboost

pip install calendar



安装fastapi:  fastapi 是一个web开发包，安装的时候一起安装上uvicorn，一个小型的web服务器

安装启动教程如下：https://fastapi.tiangolo.com/zh/tutorial/



安装prophet：https://blog.csdn.net/lx529068450/article/details/104683078

prophet教程：https://facebook.github.io/prophet/docs/quick_start.html#python-api



安装完成测试这些包是否可用



## 容器打包成镜像

容器官方推荐采用dockerfile的方式定制镜像，但是因为时间和对docker不了解，这种方式暂时放弃了

https://yeasy.gitbook.io/docker_practice/image/commit 该链接最后讨论了dockerfile方式的优点



还可以利用容器的导入导出方式，这种方式会丢失所有元数据和历史记录，仅保存容器当时的状态，相当于虚拟机快照。

但是当时没发现这种方式，应该也可以，并且体积更小：https://www.cnblogs.com/Cherry-Linux/p/8025777.html



利用docker commit 将容器打包成镜像，非常不友好，黑盒且体积巨大，不方便后期维护，但还是经验不足选择了这种方式。

容器打包成镜像：docker commit trend_pre trend_pre_image

保存镜像文件：docker save -o ./trend_pre_image.tar trend_pre_image



拷贝镜像文件到银行内网。

离线下载docker，并拷贝到银行内网：https://yeasy.gitbook.io/docker_practice/install/offline



# 内网导入docker镜像

内网测试服务器

22.188.110.147

账号：root

密码：Scyx-20210202!



安装docker：yun install *.rpm

导入docker镜像：docker load -i trend_pre_image.tar

启动容器：docker run -it --net=host --name=trend_pre trend_pre_image

进入容器 docker attach trend_pre 

激活conda环境：conda env list

conda activate trend_pre

上传代码：从容器外部执行命令将代码文件拷贝进docker指定位置。

docker cp space trend_pre:/aa 

容器中进入代码所在文件夹： cd /aa/space/web_fastapi

后台开启jupyter：nohup jypyter notebook --allow-root jupyter.log 2>&1 &

启动后，即可访问 jupyter：22.188.110.147:8888  或 22.188.110.147:8889

后台开启uvicorn: nohup uvicorn main:app --host 0.0.0.0 &



另外，还有一个定时清理docker 中 nohup.out  和   jupyter.log 两个日志的shell脚本

位于生产214.185.50.19:/opt/trend_predict 下，通过crontab设置每3天清空一次。



# 内网其他组件清单

该清单只针对测试环境，生产环境各软件清单可咨询开发运维人员。



## MySQL8.0

内网测试环境：22.188.110.145:3306

账号：root

密码：MySQL!23



该数据库中的表关系详见本把文件夹下 星图.pdm



## Elasticsearch6.0

内网测试环境：

22.188.110.143:9200

22.188.110.144:9200

22.188.110.145:9200



已知es索引：

存储历年作业的索引：twshidata2016、twshidata2017、twshidata2018、twshidata2019、twshidata2020

存储预测结果的索引：batchforecast



es教程：http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html

es查询语法：https://www.elastic.co/guide/cn/elasticsearch/guide/current/query-dsl-intro.html

python-API:https://www.cnblogs.com/remainsu/p/python-cha-xun-elasticsearch-chang-yong-fang-fa-qu.html

https://blog.csdn.net/xuezhangjun0121/article/details/80745575?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0&spm=1001.2101.3001.4242

painless脚本语言：https://www.jianshu.com/p/7518dccc0bcf

es任务管理：https://cn-blogs.cn/archives/1308.html

 

## Kafka

内网测试环境：

22.188.110.143:8050

22.188.110.144:8050

22.188.110.145:8050



用到的 topic：aiops_alert

是产品规定好的 topic，我们只是发送消息到 kafka，具体格式见代码



## consul

内网测试环境：

22.188.110.146:8500



# 算法

作业耗时预测和结束时间预测都采用的时序算法。

主要包括ARIMA 和 Prophet 两种算法，根据不同的参数，衍生了12种。



## ARIMA

简介：见时间序列算法调研

其中，主要靠measurement_error、enforce_stationarity、enforce_invertibility、concentrate_scale等参数调节预测的数值范围。

seasonal_pdq 调节预测的周期。



## Prophet 

教程：https://facebook.github.io/prophet/docs/quick_start.html#python-api

prophet 有3个主要的因素可供调节，预测的周期，预测结果灵活稳定，预测结果的范围。

其中，预测结果的范围可以直接在预测结果集中选取不同的列。

预测的周期，主要靠 weekly_seasonality参数 和 add_seasonality方法实现。

预测结果灵活稳定主要靠 changepoint_prior_scale 这个参数进行调节。



在这些基础上，还加入了法定节假日的影响。



# 作业概念

作业属于某个作业流，作业流属于系统，系统属于区域。

作业同时也属于模块，模块与作业流是平级的关系，模块是从业务角度对作业进行的划分。



# 服务

## 作业运行频率分析

因为历史上的数据运行频次不确定，对作业定时任务和作业预测分析有影响，所以需要对作业运行频率进行分析。

通过读取最近半年的数据，过程详见 job_frequence 。

结果发现，大部分作业的运行频率都是每天一次，可以近似的认为现在的作业运行是比较稳定的每天一次。



## 作业批量时间更新

因为作业调度系统 TWS 的历史原因，20年及以前的作业只有开始时间，没有批量作业的定时时间。

所以需要分析近半年有批量时间的作业，找出规律，然后用着套规则去更新历史作业的批量时间。

过程详见 batch_date 。因为是基于统计找出的规律，所以存在误差。也有部分作业近半年已经不运行了，也没有必要更新。



## 找出趋势相同作业

中行领导要求找出业务数据与作业的相关关系，因为缺少业务数据，所以暂时改成了找出趋势相同作业。此场景暂无应用。

利用 DTW时间规整算法 找出与基准红线作业 趋势相似的作业。详见代码 trend_same 。



DTW时间规整算法：

https://zhuanlan.zhihu.com/p/32849741

https://blog.csdn.net/itnerd/article/details/103735030



## 找出机构与作业的关联关系

因为作业表中没有作业与机构的关联关系，而某些报表需要找出这个关系。

有两种方法，一是根据模块与作业的关系，找出作业和机构的关系，作业属于某个模块，而模块与机构的关系是有的。

二是不同区域内的作业名称或者作业流名称和某些机构代码有不确定的匹配关系，需要进行匹配，这种方法存在误差

详见 org_job 。



## 找出业务指标与作业的相关关系

生产上没有接入业务指标，所以没有该服务。

业务指标共有4个，是每秒对某个业务指标都有一个采集值。业务指标只有21年之后的数据，与我们现有作业数据时间重合不多。



首先对作业数据进行处理，然后对业务指标进行聚合，之前是聚合到作业开始时间与结束时间，但运行太慢，所以聚合到和作业同一天，

指标相关关系，用df.corr 算出比较大的相关系数即可，没有进行进一步探索。



## 数据库同步工具otter

因上线是之前的数据同步工具不满足要求，所以探索了开源的otter进行 MySQL5.7 到 MySQL8.0 的增量数据同步需求。

详见 otter 文件夹



## 作业耗时预测分析

利用历史数据进行离线的分析，之后写成服务供下游调用。

具体步骤见代码。文件夹trend_pre

12种时序预测的算法模板也是这时候确定的。



## 作业结束时间预测分析

同 作业耗时预测分析



## 作业耗时预测

要求预测未来14天的红线作业耗时，红线作业不多，应该在300个以内。

预测的方式采用客户手动匹配作业与算法，来进行预测。



其中，计息日和月末日等特殊日需要使用之前特殊日的历史数据。

预测方法是以上一个特殊日数值为基准，模拟上一个特殊日的波动情况，来预测这个特殊日的结果。

主要是因为业务原因，历史上即使同一个特殊日不同年份的耗时也很不相同，所以采用这种方法。



最后，将预测的结果存入es的预测结果索引中。



通过fastapi将作业耗时预测和 结束时间预测部署成两个服务。

同时，需要把耗时预测 和结束时间预测两个服务注册到consul。



## 作业结束时间预测

作业结束时间也是要求预测未来14天的作业结束时间，因为结束时间时间是一个时间戳，不是一个具体数值，所以需要转化进行时序预测

将每个作业的结束时间转化成距离该作业批量开始时间的秒数，进行预测。预测出结果后，再还原成结束时间。

因为这种转化方法相当于同时预测了开始时间和耗时的总和，所以应该更加不准确。

作业结束时间除了需要将结果存入es外，还需要与预警时间和红线时间进行对比，如果超出，需发送告警到kafka。



详见web_fastapi



# web服务

web服务代码在web_fastapi的main.py文件中，web服务器使用uvicorn。

有4个服务被封装成为了web服务



## 作业耗时预测

URL : 214.185.50.19:8000/times

http请求方式：GET

请求参数：无

返回结果：
{"message":"success"}
{"message":"fail"}
{"message":"total 3 jobs, 2 already saved"}

 

## 作业结束时间预测

URL : 214.185.50.19:8000/end_time

http请求方式：GET

请求参数：无

返回结果：
{"message":"success"}
{"message":"fail"}
{"message":"total 3 jobs, 2 already saved"}



## 找出趋势相同作业

URL : 214.185.50.19:8000/trend_same

http请求方式：GET

请求参数：无

返回结果：
{"message":"success"}
{"message":"fail"}



## 找出机构与作业的关系

URL : 214.185.50.19:8000/org_job

http请求方式：GET

请求参数：无

返回结果：
{"message":"success"}
{"message":"fail"}















































